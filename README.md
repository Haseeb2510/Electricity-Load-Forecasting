# âš¡ Electricity Load Forecasting

This project focuses on forecasting **hourly electricity demand** using multiple model families and comparing how they perform under **stable conditions** and during **regime shifts** (e.g., the COVID-19 period).  
The goal is to understand **which model is best suited for different real-world forecasting contexts**.

## ğŸ¯ Objective

The project evaluates three time-series modeling approaches:

| Model Type | Model Used | Purpose |
|-----------|------------|---------|
| Tree-Based | **XGBoost** | Strong baseline for stable seasonal behavior |
| Sequence Model | **LSTM** | Learns week-long temporal patterns directly from sequences |
| Attention-Based Model | **Temporal Fusion Transformer (TFT)** | Handles multivariate relationships and adapts to regime shifts |

We compare how these models handle:

- Weekly and daily **seasonality**
- **Long-range temporal dependencies**
- **Structural changes** in demand behavior (e.g., COVID impact)

The goal is **not** to find a single â€œbestâ€ model, but to identify **which model is most appropriate for which operational scenario**.

---

## ğŸ“ Project Structure

```
customer-churn-prediction/
â”‚
â”œâ”€â”€ ğŸ“ data/                        # Data directory (add your data here)
â”‚   â”œâ”€â”€ raw/                        # Raw data
â”‚   â””â”€â”€ worked/                     # Processed data
â”‚
â”œâ”€â”€ ğŸ“ models/                      # Trained models & metrics
â”‚   â”œâ”€â”€ LSTM/
â”‚   â”œâ”€â”€ TFT/
|   |   â””â”€â”€finetuned
â”‚   â””â”€â”€ XGBoost/                 
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                
â”‚   â”œâ”€â”€ 01_Data_Preparation_EDA.ipynb                      # Explains The data preparation for the models
â”‚   â”œâ”€â”€ 02_XGBoost_Model_Training.ipynb                    # XGBoost model trainig
â”‚   â”œâ”€â”€ 03_LSTM_Model_Training.ipynb                       # LSTM model training
â”‚   â”œâ”€â”€ 04_TFT_Model_Training.ipynb                        # TFT/TFT-Tuned model training
â”‚   â””â”€â”€ 05_Conclusion_and_Model_Comparison.ipynb           # Comparison between models
â”‚
â”œâ”€â”€ ğŸ“ reports/                     # Contains various plots of every step
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ data_prep.py                # Cleaning data
â”‚   â”œâ”€â”€ EDA.py                      # Exploring the data with EDA
â”‚   â”œâ”€â”€ evaluation.py               # Evaluation of the models trained
â”‚   â”œâ”€â”€ feature_engineering.py      # Feature Engineering (lags, weather,....)
â”‚   â”œâ”€â”€ LSTM_model_trainig.py       # Full LSTM model training pipeline 
â”‚   â”œâ”€â”€ prepare_data_for_models.py  # Contains main functions to split data, transform data for models
â”‚   â”œâ”€â”€ TFT_model_trainig.py        # TFT and TFT-Tuned full model training pipeline 
â”‚   â””â”€â”€ XGBoost_model_training.py   # Full XGBoost Regression model training pipeline
â”‚
â”œâ”€â”€ main.py                         # Quick access to EDA and model trainings
â”œâ”€â”€ README.py                       # This file
â””â”€â”€ requirements.txt                # Python dependencies

```

---

## ğŸ›  Tech Stack

| Category | Tools |
|---------|-------|
| Programming | Python |
| ML Frameworks | TensorFlow / Keras, PyTorch Lightning, XGBoost |
| Data Processing | pandas, NumPy, scikit-learn |
| Visualization | matplotlib, seaborn |
| Model Storage | joblib, JSON checkpoint saving |

---

## ğŸ§¹ Data Preparation & Feature Engineering

![Model Comparison](reports\EDA\Electricity_Demand_Analysis.png)


Key preprocessing steps:

- Handled missing timestamps and small gaps (forward-fill)
- Extracted time features: `hour`, `dayofweek`, `is_weekend`, `year`
- Created lag features to model short-, medium-, and long-term memory
- Compressed correlated weather variables into **3 PCA components**
- Scaled numeric features using **StandardScaler (fit on train only)** to avoid data leakage
- **COVID Impact Analysis**: Using a binary flag `covid_period`, I compared average pre-COVID vs post-COVID demand.


The final dataset includes **both contextual and temporal features**, suitable for tree-based, recurrent, and transformer models.

---

## ğŸ¤– Models

### 1) XGBoost (Tree-Based)
- Learns from engineered lag and cyclical features
- Excellent baseline for stable demand with recurring seasonality

### 2) LSTM (Sequential Neural Network)
- 2 LSTM layers: **128 â†’ 64 units**
- Dropout + L2 regularization
- Trained on **168-hour sliding windows** (one full week of context)

### 3) Temporal Fusion Transformer (TFT)
- Uses:
  - **Attention mechanisms**
  - **Gating**
  - **Variable selection layers**
- Initially struggled during COVID regime shift â†’ **Fine-tuned** on recent data to adapt successfully

---

## ğŸ“Š Model Performance (Summary)

| Model | MAE â†“ | RMSE â†“ | MAPE â†“ | Interpretation |
|------|------|------|-------|----------------|
| **XGBoost** | Low | Low | Lowest | Best during stable seasonal behavior |
| **LSTM** | Medium | Higher | ~10% | Captures weekly structure, less precise overall |
| **TFT (initial)** | High | High | Struggled | Unable to generalize across COVID demand shift |
| **TFT (fine-tuned)** | Improved Significantly | Much Lower | ~5% | Successfully adapts to structural change |


![Model Comparison](reports/model_comparison/model_comparison.png)

---

## ğŸ“ˆ Visual Results

- Prediction vs. Actual overlays
- Error (residual) diagnostics
- Model comparison bar charts

All visuals are available in the repositoryâ€™s **`reports/`** folder and inside the **Model Comparison Notebook**.

---

## ğŸš€ Run the Project

```bash
# Clone repository
git clone <https://github.com/Haseeb2510/Electricity-Load-Forecasting>

# Install dependencies
pip install -r requirements.txt

```

## ğŸ›  Run `main.py` for a quick overview of:

1. Evaluation
2. EDA
3. XGBoost model Training
4. LSTM model Training
5. TFT (Temporal Frusion Transformer) model Training

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¨â€ğŸ’» Author

**Your Name**
- GitHub: [@Haseeb2510](https://github.com/Haseeb2510)
- LinkedIn: [Abdul Haseeb](https://www.linkedin.com/in/haseeb-abdul-172542243)

## ğŸ‰ Acknowledgments

This project was made possible through the contributions of the open-source community and publicly available data resources.

Special thanks to:

- **Saurabh Shahane** and **Kaggle** for providing the Electricity Load Forecasting dataset, which served as the foundation for this project.
- **PyTorch Forecasting**, **TensorFlow/Keras**, and **XGBoost** teams for developing high-performance frameworks for sequence and tree-based modeling.
- **scikit-learn**, **Pandas**, and **NumPy** for their essential data processing, transformation, and evaluation utilities.
- **Matplotlib** and **Seaborn** for visualization tools that made analysis and interpretation clear.


Grateful to the open-source ecosystem for enabling accessible, reproducible, and high-quality machine learning development.
